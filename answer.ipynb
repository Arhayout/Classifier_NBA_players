{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score_classifier(dataset,classifier,labels):\n",
    "\n",
    "    \"\"\"\n",
    "    performs 3 random trainings/tests to build a confusion matrix and prints results with precision and recall scores\n",
    "    :param dataset: the dataset to work on\n",
    "    :param classifier: the classifier to use\n",
    "    :param labels: the labels used for training and validation\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    kf = KFold(n_splits=3,random_state=50,shuffle=True)\n",
    "    confusion_mat = np.zeros((2,2))\n",
    "    # Recall = TP / (TP + FN)\n",
    "    \n",
    "    recall = 0\n",
    "    for training_ids,test_ids in kf.split(dataset):\n",
    "        training_set = dataset[training_ids]\n",
    "        training_labels = labels[training_ids]\n",
    "        test_set = dataset[test_ids]\n",
    "        test_labels = labels[test_ids]\n",
    "        classifier.fit(training_set,training_labels)\n",
    "        predicted_labels = classifier.predict(test_set)\n",
    "        confusion_mat+=confusion_matrix(test_labels,predicted_labels)\n",
    "        recall += recall_score(test_labels, predicted_labels)\n",
    "    recall/=3\n",
    "    print(confusion_mat)\n",
    "    return recall \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[271. 238.]\n",
      " [145. 686.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82551959002102"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"nba_logreg.csv\")\n",
    "\n",
    "# extract names, labels, features names and values\n",
    "names = df['Name'].values.tolist() # players names\n",
    "labels = df['TARGET_5Yrs'].values # labels\n",
    "paramset = df.drop(['TARGET_5Yrs','Name'],axis=1).columns.values\n",
    "df_vals = df.drop(['TARGET_5Yrs','Name'],axis=1).values\n",
    "\n",
    "# replacing Nan values (only present when no 3 points attempts have been performed by a player)\n",
    "for x in np.argwhere(np.isnan(df_vals)):\n",
    "    df_vals[x]=0.0\n",
    "\n",
    "# normalize dataset\n",
    "X = MinMaxScaler().fit_transform(df_vals)\n",
    "\n",
    "#example of scoring with support vector classifier\n",
    "score_classifier(X,SVC(),labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27161/2980392707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# define a list of classifiers to try\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m classifiers = [SVC(), RandomForestClassifier(), LogisticRegression(), KNeighborsClassifier(),\n\u001b[0m\u001b[1;32m      3\u001b[0m  \u001b[0mRidgeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  QuadraticDiscriminantAnalysis(), KNeighborsClassifier()]\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# define a list of classifiers to try\n",
    "classifiers = [SVC(), RandomForestClassifier(), LogisticRegression(), KNeighborsClassifier(),\n",
    " RidgeClassifier(), AdaBoostClassifier(), GradientBoostingClassifier(), MLPClassifier(), LinearDiscriminantAnalysis(),\n",
    " QuadraticDiscriminantAnalysis(), KNeighborsClassifier()]\n",
    "\n",
    "# train each classifier and evaluate performance using score_classifier function\n",
    "best_recall = 0\n",
    "best_clf = None\n",
    "for clf in classifiers:\n",
    "    score = score_classifier(X, clf, labels)\n",
    "    if score > best_recall:\n",
    "        best_recall = score\n",
    "        best_clf = clf\n",
    "\n",
    "print(\"Best classifier with recall score of {}: {}\".format(best_recall, best_clf))\n",
    "import pickle\n",
    "\n",
    "# best_clf is the trained model\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_clf, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:8080\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [21/Apr/2023 15:47:53] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [21/Apr/2023 15:47:54] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained model\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "\n",
    "# Define the API endpoint\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get the request data as a dictionary\n",
    "    data = request.get_json(force=True)\n",
    "\n",
    "    # Transform the data into a numpy array\n",
    "    data_arr = np.array([data['GP'], data['MIN'], data['PTS'], data['FGM'], data['FGA'], data['FG%'], data['3P Made'], data['3PA'], data['3P%'], data['FTM'], data['FTA'], data['FT%'], data['OREB'], data['DREB'], data['REB'], data['AST'], data['STL'], data['BLK'], data['TOV']]).reshape(1, -1)\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(data_arr)\n",
    "\n",
    "    # Convert the prediction to a boolean value\n",
    "    prediction = bool(prediction[0])\n",
    "\n",
    "    # Return the prediction as a JSON response\n",
    "    return jsonify(prediction=prediction)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "     app.run(debug=True ,port=8080,use_reloader=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
